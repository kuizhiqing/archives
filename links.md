## References
### ./2012
* [算子与线性常微分方程(上) - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/1791)
* [算子与线性常微分方程(下) - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/1794)
### ./2013
* [LDA-math - 神奇的 Gamma 函数 _ 统计之都.mhtml](https://cosx.org/2013/01/lda-math-gamma-function)
### ./2014
* [CUDA Pro Tip_ Optimize for Pointer Aliasing _ NVIDIA Technical Blog.mhtml](https://developer.nvidia.com/blog/cuda-pro-tip-optimize-pointer-aliasing/)
* [算符的艺术：差分、微分与伯努利数 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/3018)
* [伽马函数的傅里叶变换之路 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/3108)
### ./2015
* [“熵”不起：从熵、最大熵原理到最大熵模型（一） - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/3534)
### ./2016
* [Asio Implementation - spirits away.mhtml](http://spiritsaway.info/asio-implementation.html)
### ./2017
* [SVD分解(三)：连Word2Vec都只不过是个SVD？ - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/4233)
* [梯度下降和EM算法：系出同源，一脉相承 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/4277)
* [SVD分解(二)：为什么SVD意味着聚类？ - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/4216)
* [SVD分解(一)：自编码器与人工智能 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/4208)
### ./2018
* [变分自编码器 = 最小化先验分布 + 最大化互信息 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/6088)
* [变分自编码器（二）：从贝叶斯观点出发 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/5343)
* [用变分推断统一理解生成模型（VAE、GAN、AAE、ALI） - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/5716)
* [深度学习的互信息：无监督提取特征 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/6024)
* [《Attention is All You Need》浅读（简介+代码） - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/4765)
* [从变分编码、信息瓶颈到正态分布：论遗忘的重要性 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/6181)
* [最小熵原理（一）：无监督学习的原理 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/5448)
* [变分自编码器（三）：这样做为什么能成？ - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/5383)
* [变分自编码器（一）：原来是这么一回事 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/5253)
* [变分自编码器（四）：一步到位的聚类方案 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/5887)
### ./2019
* [PyTorch internals _ ezyang’s blog.mhtml](http://blog.ezyang.com/2019/05/pytorch-internals/)
* [Attn_ Illustrated Attention. Attention illustrated in GIFs and how… _ by Raimi Karim _ Towards Data Science.mhtml](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)
* [从语言模型到Seq2Seq：Transformer如戏，全靠Mask - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/6933)
* [Understanding Variational Autoencoders (VAEs) _ by Joseph Rocca _ Towards Data Science.mhtml](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)
* [从去噪自编码器到生成模型 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/7038)
* [VQ-VAE的简明介绍：量子化自编码器 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/6760)
### ./2020
* [A brief taxonomy of PyTorch operators by shape behavior _ ezyang’s blog.mhtml](http://blog.ezyang.com/2020/05/a-brief-taxonomy-of-pytorch-operators-by-shape-behavior/)
* [变分自编码器（五）：VAE + BN = 更好的VAE - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/7381)
* [连接跟踪（conntrack）：原理、应用及 Linux 内核实现.mhtml](http://arthurchiao.art/blog/conntrack-design-and-implementation-zh/)
* [Connection Tracking (conntrack)_ Design and Implementation Inside Linux Kernel.mhtml](http://arthurchiao.art/blog/conntrack-design-and-implementation/)
* [PyTorch TensorIterator Internals _ Quansight Labs.mhtml](https://labs.quansight.org/blog/2020/04/pytorch-tensoriterator-internals)
* [绕过conntrack，使用eBPF增强 IPVS优化K8s网络性能 - 腾讯云开发者社区-腾讯云.mhtml](https://cloud.tencent.com/developer/article/1687922)
* [突破瓶颈，打造更强大的Transformer - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/7325)
* [Let’s talk about the PyTorch dispatcher _ ezyang’s blog.mhtml](http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/)
* [乘风破浪的PTM：两年来预训练模型的技术进展 - 知乎.mhtml](https://zhuanlan.zhihu.com/p/254821426)
* [Linux I_O 原理和 Zero-copy 技术全面揭秘 - 知乎.mhtml](https://zhuanlan.zhihu.com/p/308054212)
* [EAE：自编码器 + BN + 最大熵 = 生成模型 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/7343)
* [变分自编码器（六）：从几何视角来理解VAE的尝试 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/7725)
* [层次分解位置编码，让BERT可以处理超长文本 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/7947)
* [线性Attention的探索：Attention必须有个Softmax吗？ - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/7546)
### ./2021
* [A Simple Example of Causal Attention Masking in Transformer Decoder _ by Jinoo Baek _ Medium.mhtml](https://medium.com/@jinoo/a-simple-example-of-attention-masking-in-transformer-decoder-a6c66757bc7d)
* [华为昇腾910使用初探 · wu-kan.mht](https://wu-kan.cn/2021/03/21/%E5%8D%8E%E4%B8%BA%E6%98%87%E8%85%BE910%E4%BD%BF%E7%94%A8%E5%88%9D%E6%8E%A2/)
* [变分自编码器（八）：估计样本概率密度 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/8791)
* [Transformer升级之路：3、从Performer到线性Attention - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8338)
* [Transformer升级之路：5、作为无限维的线性Attention - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8601)
* [资源依赖的“诅咒” _ 原有深度学习框架的缺陷①.mhtml](https://mp.weixin.qq.com/s?__biz=MzU5ODY2MTk3Nw==&mid=2247485374&idx=1&sn=9c32f769153d295398061e8225f4eadb&chksm=fe418988c936009e956b26bcd79fc1c05d98f3e170622bbd110ec3e707d4f74a7d5a2a5bb762&scene=21#wechat_redirect)
* [线性Transformer应该不是你要等的那个模型 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8610)
* [让研究人员绞尽脑汁的Transformer位置编码 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8130)
* [从熵不变性看Attention的Scale操作 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/8823)
* [数据搬运的“诅咒” _ 原有深度学习框架的缺陷② - 知乎.mhtml](https://zhuanlan.zhihu.com/p/379311974)
* [变分自编码器（七）：球面上的VAE（vMF-VAE） - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/8404)
* [Transformer升级之路：2、博采众长的旋转式位置编码 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8265)
* [GPT-3模型为何难以复现？这也许是分布式AI框架的最优设计.mhtml](https://mp.weixin.qq.com/s/YQshbDYgfYCO9POH7Ls3cw)
* [Transformer升级之路：1、Sinusoidal位置编码追根溯源 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8231)
* [一文搞懂容器运行时 Containerd-阳明的博客_Kubernetes_Istio_Prometheus_Python_Golang_云原生.mhtml](https://www.qikqiak.com/post/containerd-usage/)
* [一文搞定 _ Linux共享内存原理 - 腾讯云开发者社区-腾讯云.mhtml](https://cloud.tencent.com/developer/article/1878790)
* [浅谈Transformer的初始化、参数化与标准化 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8620)
* [Nyströmformer：基于矩阵分解的线性化Attention方案 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8180)
* [Transformer升级之路：4、二维位置的旋转式位置编码 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8397)
### ./2022
* [logsumexp运算的几个不等式 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9070)
* [用热传导方程来指导自监督学习 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/9359)
* [FLASH：可能是近来最有意思的高效Transformer设计 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/8934)
* [Generative AI_ A Creative New World _ Sequoia Capital US_Europe.mhtml](https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/)
* [Field Theory Fundamentals in 20 Minutes — Physics with Elliot.mhtml](https://www.physicswithelliot.com/fields-mini-notes)
* [熵不变性Softmax的一个快速推导 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/9034)
* [Transformer升级之路：6、旋转位置编码的完备性分析 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9403)
* [Discovering the Fourier Transform Through Quantum Mechanics — Physics with Elliot.mhtml](https://www.physicswithelliot.com/fourier-mini-notes)
* [听说Attention与Softmax更配哦～ - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9019)
* [Learning PyTorch with Examples — PyTorch Tutorials 1.13.0+cu117 documentation.mht](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#examples-download)
* [MLOps Is a Mess But That's to be Expected - Mihail Eric.mhtml](https://www.mihaileric.com/posts/mlops-is-a-mess/)
### ./2023
* [Transformer升级之路：7、长度外推性与局部注意力 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9431)
* [Google新搜出的优化器Lion：效率与效果兼得的“训练狮” - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9473)
* [通向AGI之路：大型语言模型（LLM）技术精要 - 知乎.mhtml](https://zhuanlan.zhihu.com/p/597586623)
* [专栏 - PingCAP 黄东旭万字长文剖析数据库发展新趋势：脱离应用开发者的数据库，不会成功 _ TiDB 社区.mhtml](https://tidb.net/blog/14852c31)
* [CUDA C++ Programming Guide.mhtml](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)
* [Transformer升级之路：8、长度外推性与位置鲁棒性 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9444)
* [Stanford CRFM.mhtml](https://crfm.stanford.edu/2023/01/13/flashattention.html)
* [生成扩散模型漫谈（十六）：W距离 ≤ 得分匹配 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9467)
### ./manual
* [PEP 8 – Style Guide for Python Code _ peps.python.org.mhtml](https://peps.python.org/pep-0008/)
### ./mathematics
### ./slides
### ./unknown
* [huihut_interview_ 📚 C_C++ 技术面试基础知识总结，包括语言、程序库、数据结构、算法、系统、网络、链接装载库等知识及面试经验、招聘、内推等信息。This repository is a summary of the basic knowled.mhtml](https://github.com/huihut/interview#database)
