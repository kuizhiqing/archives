## Links
* [PyTorch internals _ ezyang’s blog.mhtml](http://blog.ezyang.com/2019/05/pytorch-internals/)
* [Attn_ Illustrated Attention. Attention illustrated in GIFs and how… _ by Raimi Karim _ Towards Data Science.mhtml](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)
* [从语言模型到Seq2Seq：Transformer如戏，全靠Mask - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/6933)
* [Understanding Variational Autoencoders (VAEs) _ by Joseph Rocca _ Towards Data Science.mhtml](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)
* [从去噪自编码器到生成模型 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/7038)
* [VQ-VAE的简明介绍：量子化自编码器 - 科学空间_Scientific Spaces.mhtml](https://spaces.ac.cn/archives/6760)
