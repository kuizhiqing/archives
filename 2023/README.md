## Links
* [Transformer升级之路：7、长度外推性与局部注意力 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9431)
* [Google新搜出的优化器Lion：效率与效果兼得的“训练狮” - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9473)
* [通向AGI之路：大型语言模型（LLM）技术精要 - 知乎.mhtml](https://zhuanlan.zhihu.com/p/597586623)
* [专栏 - PingCAP 黄东旭万字长文剖析数据库发展新趋势：脱离应用开发者的数据库，不会成功 _ TiDB 社区.mhtml](https://tidb.net/blog/14852c31)
* [CUDA C++ Programming Guide.mhtml](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)
* [Transformer升级之路：8、长度外推性与位置鲁棒性 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9444)
* [Stanford CRFM.mhtml](https://crfm.stanford.edu/2023/01/13/flashattention.html)
* [生成扩散模型漫谈（十六）：W距离 ≤ 得分匹配 - 科学空间_Scientific Spaces.mhtml](https://kexue.fm/archives/9467)
